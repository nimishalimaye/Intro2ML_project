{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNIST data...\n",
      "l1coef = 0.000000, l2coef = 0.000000\n",
      "Training MNIST data...\n",
      "0 :   0.9414\n",
      "1 :   0.9635\n",
      "2 :   0.9728\n",
      "3 :   0.9722\n",
      "4 :   0.9757\n",
      "Accuracy is:     0.9757\n",
      "Confidence is:     0.979741023985\n",
      "l1coef = 0.000000, l2coef = 0.000100\n",
      "Training MNIST data...\n",
      "0 :   0.9785\n",
      "1 :   0.976\n",
      "2 :   0.977\n",
      "3 :   0.979\n",
      "4 :   0.9793\n",
      "Accuracy is:     0.9793\n",
      "Confidence is:     0.983477926008\n",
      "l1coef = 0.000000, l2coef = 0.000010\n",
      "Training MNIST data...\n",
      "0 :   0.9828\n",
      "1 :   0.9826\n",
      "2 :   0.9822\n",
      "3 :   0.9826\n",
      "4 :   0.9828\n",
      "Accuracy is:     0.9828\n",
      "Confidence is:     0.988151661535\n",
      "l1coef = 0.000100, l2coef = 0.000000\n",
      "Training MNIST data...\n",
      "0 :   0.9741\n",
      "1 :   0.9691\n",
      "2 :   0.9659\n",
      "3 :   0.9651\n",
      "4 :   0.9684\n",
      "Accuracy is:     0.9684\n",
      "Confidence is:     0.956141817953\n",
      "l1coef = 0.000100, l2coef = 0.000100\n",
      "Training MNIST data...\n",
      "0 :   0.9673\n",
      "1 :   0.9662\n",
      "2 :   0.9676\n",
      "3 :   0.9654\n",
      "4 :   0.9679\n",
      "Accuracy is:     0.9679\n",
      "Confidence is:     0.959373068535\n",
      "l1coef = 0.000100, l2coef = 0.000010\n",
      "Training MNIST data...\n",
      "0 :   0.9684\n",
      "1 :   0.969\n",
      "2 :   0.9695\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ea89432cf63d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;31m# Show test set accuracy. Its cost is not used for optimization,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;31m# it is just to show progress.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m':  '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m                 \u001b[0;31m# In each step save the learned weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;31m#with open('LearnedParamsL1.model','wb') as fp:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Deepak/anaconda/lib/python3.6/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Deepak/anaconda/lib/python3.6/site-packages/theano/gof/op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m                     \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Deepak/anaconda/lib/python3.6/site-packages/theano/tensor/basic.py\u001b[0m in \u001b[0;36mperform\u001b[0;34m(self, node, inp, out)\u001b[0m\n\u001b[1;32m   5783\u001b[0m         \u001b[0;31m# gives a numpy float object but we need to return a 0d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5784\u001b[0m         \u001b[0;31m# ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5785\u001b[0;31m         \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5787\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import theano\n",
    "from theano import tensor as T\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "import numpy as np\n",
    "import pickle as cPickle \n",
    "import os\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "#from pprint import pprint\n",
    "srng = RandomStreams()\n",
    "\n",
    "TRAINING = True\n",
    "\n",
    "# Convert into correct type for theano\n",
    "def floatX(X):\n",
    "    return np.asarray(X, dtype=theano.config.floatX)\n",
    "\n",
    "# Weights are shared theano variables\n",
    "def init_weights(shape):\n",
    "    return theano.shared(floatX(np.random.randn(*shape) * 0.01))\n",
    "\n",
    "# RMSProp to update weights\n",
    "def RMSprop(cost, params, lr=0.001, rho=0.9, epsilon=1e-6):\n",
    "    grads = T.grad(cost=cost, wrt=params)\n",
    "    updates = []\n",
    "    for p, g in zip(params, grads):\n",
    "        acc = theano.shared(p.get_value() * 0.)\n",
    "        acc_new = rho * acc + (1 - rho) * g ** 2\n",
    "        gradient_scaling = T.sqrt(acc_new + epsilon)\n",
    "        g = g / gradient_scaling\n",
    "        updates.append((acc, acc_new))\n",
    "        updates.append((p, p - lr * g))\n",
    "    return updates\n",
    "\n",
    "# Dropout regularization \n",
    "def dropout(X, p=0.):\n",
    "    if p > 0:\n",
    "        retain_prob = 1 - p\n",
    "        X *= srng.binomial(X.shape, p=retain_prob, dtype=theano.config.floatX)\n",
    "        X /= retain_prob\n",
    "    return X\n",
    "\n",
    "# Neural network model, 3 fully connected layers\n",
    "def model(X, w_h, w_h2, w_o, p_drop_input, p_drop_hidden):\n",
    "\t# Input layer: dropout + relu \n",
    "    X = dropout(X, p_drop_input)\n",
    "    h = T.nnet.relu(T.dot(X, w_h))\n",
    "\t\n",
    "\t# Hidden layer: dropout + relu \n",
    "    h = dropout(h, p_drop_hidden)\n",
    "    h2 = T.nnet.relu(T.dot(h, w_h2))\n",
    "\t\n",
    "\t# Output layer: dropout + softmax \n",
    "    h2 = dropout(h2, p_drop_hidden)\n",
    "    py_x = T.nnet.softmax(T.dot(h2, w_o))\n",
    "    return h, h2, py_x\n",
    "\n",
    "def one_hot(x,n):\n",
    "\tif type(x) == list:\n",
    "\t\tx = np.array(x)\n",
    "\tx = x.flatten()\n",
    "\to_h = np.zeros((len(x),n))\n",
    "\to_h[np.arange(len(x)),x] = 1\n",
    "\treturn o_h\n",
    "\n",
    "def mnist(ntrain=60000,ntest=10000,onehot=True):\n",
    "\tdata_dir = os.path.join(datasets_dir,'mnist/')\n",
    "\tfd = open(os.path.join(data_dir,'train-images-idx3-ubyte'))\n",
    "\tloaded = np.fromfile(file=fd,dtype=np.uint8)\n",
    "\ttrX = loaded[16:].reshape((60000,28*28)).astype(float)\n",
    "\n",
    "\tfd = open(os.path.join(data_dir,'train-labels-idx1-ubyte'))\n",
    "\tloaded = np.fromfile(file=fd,dtype=np.uint8)\n",
    "\ttrY = loaded[8:].reshape((60000))\n",
    "\n",
    "\tfd = open(os.path.join(data_dir,'t10k-images-idx3-ubyte'))\n",
    "\tloaded = np.fromfile(file=fd,dtype=np.uint8)\n",
    "\tteX = loaded[16:].reshape((10000,28*28)).astype(float)\n",
    "\n",
    "\tfd = open(os.path.join(data_dir,'t10k-labels-idx1-ubyte'))\n",
    "\tloaded = np.fromfile(file=fd,dtype=np.uint8)\n",
    "\tteY = loaded[8:].reshape((10000))\n",
    "\n",
    "\ttrX = trX/255.\n",
    "\tteX = teX/255.\n",
    "\n",
    "\ttrX = trX[:ntrain]\n",
    "\ttrY = trY[:ntrain]\n",
    "\n",
    "\tteX = teX[:ntest]\n",
    "\tteY = teY[:ntest]\n",
    "\n",
    "\tif onehot:\n",
    "\t\ttrY = one_hot(trY, 10)\n",
    "\t\tteY = one_hot(teY, 10)\n",
    "\telse:\n",
    "\t\ttrY = np.asarray(trY)\n",
    "\t\tteY = np.asarray(teY)\n",
    "\n",
    "\treturn trX,teX,trY,teY\n",
    "\n",
    "datasets_dir = 'media/datasets/'\n",
    "srng = RandomStreams()\n",
    "TRAINING = True\n",
    "\n",
    "print('Loading MNIST data...')\n",
    "trX, teX, trY, teY = mnist(onehot=True)\n",
    "\n",
    "# Initialize theano variables for X, Y, and shared variables for weights\n",
    "X = T.fmatrix()\n",
    "Y = T.fmatrix()\n",
    "\n",
    "if TRAINING:\n",
    "    # For training of the net, we initialize weights to random values\n",
    "    w_h = init_weights((784, 625))\n",
    "    w_h2 = init_weights((625, 625))\n",
    "    w_o = init_weights((625, 10))\n",
    "    params = [w_h, w_h2, w_o]\n",
    "else:\n",
    "    # To run experiments, just read weights we learned before\n",
    "    print('Loading model...') \n",
    "    #with open('LearnedParamsL1.model','rb') as fp:\n",
    "        #params = cPickle.load(fp)\n",
    "    w_h, w_h2, w_o = params\n",
    "\n",
    "# Dropout model for training\n",
    "noise_h, noise_h2, noise_py_x = model(X, w_h, w_h2, w_o, 0.2, 0.5)\n",
    "# Use all-weights model for prediction\n",
    "h, h2, py_x = model(X, w_h, w_h2, w_o, 0., 0.)\n",
    "y_x = T.argmax(py_x, axis=1)\n",
    "\n",
    "# To find confidence of test set use the following value of y_x\n",
    "y_x1 = T.max(py_x, axis = 1)\n",
    "# Define cost and update theano expressions\n",
    "\n",
    "l1 = abs(w_h).sum() + abs(w_h2).sum() + abs(w_o).sum()\n",
    "l2 = (w_h**2).sum() + (w_h2**2).sum() + (w_o**2).sum()\n",
    "\n",
    "#==========================Training for blue team==========================#\n",
    "\n",
    "#=================== Parameters to change ===============================#\n",
    "l1coef = [ 0.0, 0.0001, 0.00001 ] \n",
    "l2coef = [ 0.0, 0.0001, 0.00001 ] \n",
    "#=======================================================================#\n",
    "\n",
    "for l in l1coef:\n",
    "    for j in l2coef:\n",
    "        print(\"l1coef = %f, l2coef = %f\" %(l,j))\n",
    "        cost = T.mean(T.nnet.categorical_crossentropy(noise_py_x, Y)) + l * l1 + j * l2\n",
    "        updates = RMSprop(cost, params, lr=0.001)\n",
    "\n",
    "        # Define train and predict theano functions\n",
    "        train = theano.function(inputs=[X, Y], outputs=cost, updates=updates, allow_input_downcast=True)\n",
    "\n",
    "        predict = theano.function(inputs=[X], outputs=y_x, allow_input_downcast=True)\n",
    "        predict_conf = theano.function(inputs=[X], outputs=y_x1, allow_input_downcast=True)\n",
    "        \n",
    "        if TRAINING:\n",
    "            print('Training MNIST data...')\n",
    "            # Train in 5 epochs\n",
    "            for k in range(5):\n",
    "                # Select minibatch and train\n",
    "                for start, end in zip(range(0, len(trX), 128), range(128, len(trX), 128)):\n",
    "                    cost = train(trX[start:end], trY[start:end])\n",
    "                # Show test set accuracy. Its cost is not used for optimization,\n",
    "                # it is just to show progress.\n",
    "                print(k, ':  ', np.mean(np.argmax(teY, axis=1) == predict(teX)))\n",
    "                # In each step save the learned weights\n",
    "                #with open('LearnedParamsL1.model','wb') as fp:\n",
    "                    #cPickle.dump(params,fp)\n",
    "            print(\"Accuracy is:    \",np.mean(np.argmax(teY, axis=1) == predict(teX)))\n",
    "            print(\"Confidence is:    \", np.mean(predict_conf(teX)))\n",
    "#____________________________________________________________________________________________\n",
    "#\n",
    "# Now we have a trained model, either loaded or trained\n",
    "# Time to create adversarial examples and test them \n",
    "   \n",
    "# Theano function which calculates gradient of the cost function w.r.t. input image\n",
    "cost_ad = T.mean(T.nnet.categorical_crossentropy(py_x, Y))\n",
    "get_grad = theano.function(inputs=[X, Y], outputs=T.grad(cost_ad, X), allow_input_downcast=True)\n",
    "\n",
    "def plot_mnist_digit(image1, image2, name1, name2):\n",
    "    global count_attack\n",
    "    image1 = np.reshape(image1,[1,784])\n",
    "    image2 = np.reshape(image2,[1,784])\n",
    "    #print 'test image confidence' , np.mean(predict_conf(image1)), 'adversarial image confidence', np.mean(predict_conf(image2))\n",
    "    #if (predict(image1) != predict(image2)):\n",
    "\t#count_attack = count_attack + 1\n",
    "\n",
    "#============================Parameter to change ========================================#\n",
    "eps_values = [0.10, 0.25]  \n",
    "#========================================================================================#\n",
    "\n",
    "for EPS in eps_values:\n",
    "    eps = EPS\n",
    "    adX = []\n",
    "    for i in range(len(teX)):\n",
    "        gs = get_grad(teX[i:i+1], teY[i:i+1]).T[:,0]\n",
    "        img_ad = teX[i] + eps * np.sign(gs) \n",
    "        adX.append(img_ad)\n",
    "\n",
    "    # Find accuracy of the classifier on the test set and adversarial set\n",
    "    pred_teY = predict(teX)\n",
    "    #print 'Test set Accuracy:\t\t\t\t\t', np.mean(np.argmax(teY, axis=1) == predict(teX)) \n",
    "    print('Adversarial set Accuracy, e=', eps, ':\t\t\t', np.mean(np.argmax(teY, axis=1) == predict(adX)))\n",
    "    #np.mean(predict(adX)!=Yts)\n",
    "    #print 'Test Set Confidence:\t\t\t\t\t', np.mean(predict_conf(teX))\n",
    "    print('Adversarial set Confidence:\t\t\t\t', np.mean(predict_conf(adX)))\n",
    "    #count_attack = 0\n",
    "    #for i in range(len(teX)):     \n",
    "       #plot_mnist_digit(teX[i], adX[i], 'test_img{0}.jpg'.format(i),'less_ad_img{0}.jpg'.format(i))\n",
    "\n",
    "    #print 'Percent of successful adversarial attack:{0:3f}:\t\t\t\t\t\t\t' .format(float(count_attack*100)/len(teX))\n",
    "    print('================================================================================')\n",
    "\n",
    "'''\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(noise_py_x, Y)) + l1coef * l1 + l2coef * l2\n",
    "updates = RMSprop(cost, params, lr=0.001)\n",
    "\n",
    "# Define train and predict theano functions\n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=updates, allow_input_downcast=True)\n",
    "\n",
    "predict = theano.function(inputs=[X], outputs=y_x, allow_input_downcast=True)\n",
    "predict_conf = theano.function(inputs=[X], outputs=y_x1, allow_input_downcast=True)\n",
    "if TRAINING:\n",
    "    # Train in 50 epochs\n",
    "    for i in range(50):\n",
    "        # Select minibatch and train\n",
    "        for start, end in zip(range(0, len(trX), 128), range(128, len(trX), 128)):\n",
    "            cost = train(trX[start:end], trY[start:end])\n",
    "        # Show test set accuracy. Its cost is not used for optimization,\n",
    "        # it is just to show progress.\n",
    "        print i, ':  ', np.mean(np.argmax(teY, axis=1) == predict(teX))\n",
    "        #print(\"In Training\")\n",
    "        # In each step save the learned weights\n",
    "        with open('LearnedParamsL1.model','wb') as fp:\n",
    "            cPickle.dump(params,fp)\n",
    "print(\"Accuracy is:    \",np.mean(np.argmax(teY, axis=1) == predict(teX)))\n",
    "print(\"Confidence is:    \", np.mean(predict_conf(teX)))\n",
    "\n",
    "def noisy(noise_typ,image):\n",
    "    if noise_typ == \"gauss\":\n",
    "        row,col,ch= image.shape\n",
    "        mean = 0\n",
    "        var = 0.1\n",
    "        sigma = var**0.5\n",
    "        gauss = np.random.normal(mean,sigma,(row,col,ch))\n",
    "        gauss = gauss.reshape(row,col,ch)\n",
    "        noisy = image + gauss\n",
    "        return noisy\n",
    "    elif noise_typ == \"s&p\":\n",
    "        row,col,ch = image.shape\n",
    "        s_vs_p = 0.5\n",
    "        amount = 0.004\n",
    "        out = np.copy(image)\n",
    "        #Salt mode\n",
    "        num_salt = np.ceil(amount * image.size * s_vs_p)\n",
    "        coords = [np.random.randint(0, int(num_salt)) for i in image.shape]\n",
    "        out[coords] = 1\n",
    "\n",
    "        # Pepper mode\n",
    "        num_pepper = np.ceil(amount* image.size * (1. - s_vs_p))\n",
    "        coords = [np.random.randint(0, int(num_pepper)) for i in image.shape]\n",
    "        out[coords] = 0\n",
    "        return out\n",
    "    elif noise_typ == \"poisson\":\n",
    "        vals = len(np.unique(image))\n",
    "        vals = 2 ** np.ceil(np.log2(vals))\n",
    "        noisy = np.random.poisson(image * vals) / float(vals)\n",
    "        return noisy\n",
    "    elif noise_typ ==\"speckle\":\n",
    "        row,col,ch = image.shape\n",
    "        gauss = np.random.randn(row,col,ch)\n",
    "        gauss = gauss.reshape(row,col,ch)        \n",
    "        noisy = image + image * gauss\n",
    "        return noisy\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "noises = [\"gauss\",\"s&p\",'poisson','speckle']\n",
    "for noise in noises:\n",
    "    print(\"For noise: \",noise)\n",
    "    adX = []\n",
    "    for i in range(len(teX)):\n",
    "        image = np.resize(teX[i],(28,28,1))\n",
    "        img_ad = teX[i] + noisy(noise,image) \n",
    "        adX.append(img_ad)\n",
    "    print(\"Accuracy after adding noise is:    \",np.mean(np.argmax(teY, axis=1) == predict(adX)))\n",
    "    print(\"Confidence after adding noise is:    \", np.mean(predict_conf(adX)))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
