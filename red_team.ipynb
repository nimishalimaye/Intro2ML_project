{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red Team Accuracy and Confidence with e = 0.05, 0.075, 0.15, 0.175, 0.20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the necessary modules like theano, tensor, sandbox, numpy, pickle, matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "from theano import tensor as T\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle as cPickle \n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the required functions to make use of weights, RMS prop, Neural Network model, one hot and MNIST train, test and digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################## Taken from https://github.com/robertlacok/mnist-adversarial-examples #########################\n",
    "################### Taken from https://github.com/Newmu/Theano-Tutorials/ #######################################\n",
    "# Convert into correct type for theano\n",
    "def floatX(X):\n",
    "    return np.asarray(X, dtype=theano.config.floatX)\n",
    "\n",
    "# Weights are shared theano variables\n",
    "def init_weights(shape):\n",
    "    return theano.shared(floatX(np.random.randn(*shape) * 0.01))\n",
    "\n",
    "# RMSProp to update weights\n",
    "def RMSprop(cost, params, lr=0.001, rho=0.9, epsilon=1e-6):\n",
    "    grads = T.grad(cost=cost, wrt=params)\n",
    "    updates = []\n",
    "    for p, g in zip(params, grads):\n",
    "        acc = theano.shared(p.get_value() * 0.)\n",
    "        acc_new = rho * acc + (1 - rho) * g ** 2\n",
    "        gradient_scaling = T.sqrt(acc_new + epsilon)\n",
    "        g = g / gradient_scaling\n",
    "        updates.append((acc, acc_new))\n",
    "        updates.append((p, p - lr * g))\n",
    "    return updates\n",
    "\n",
    "# Dropout regularization \n",
    "def dropout(X, p=0.):\n",
    "    if p > 0:\n",
    "        retain_prob = 1 - p\n",
    "        X *= srng.binomial(X.shape, p=retain_prob, dtype=theano.config.floatX)\n",
    "        X /= retain_prob\n",
    "    return X\n",
    "\n",
    "# Neural network model, 3 fully connected layers\n",
    "def model(X, w_h, w_h2, w_o, p_drop_input, p_drop_hidden):\n",
    "\t# Input layer: dropout + relu \n",
    "    X = dropout(X, p_drop_input)\n",
    "    h = T.nnet.relu(T.dot(X, w_h))\n",
    "\t\n",
    "\t# Hidden layer: dropout + relu \n",
    "    h = dropout(h, p_drop_hidden)\n",
    "    h2 = T.nnet.relu(T.dot(h, w_h2))\n",
    "\t\n",
    "\t# Output layer: dropout + softmax \n",
    "    h2 = dropout(h2, p_drop_hidden)\n",
    "    py_x = T.nnet.softmax(T.dot(h2, w_o))\n",
    "    return h, h2, py_x\n",
    "\n",
    "def one_hot(x,n):\n",
    "\tif type(x) == list:\n",
    "\t\tx = np.array(x)\n",
    "\tx = x.flatten()\n",
    "\to_h = np.zeros((len(x),n))\n",
    "\to_h[np.arange(len(x)),x] = 1\n",
    "\treturn o_h\n",
    "\n",
    "def mnist(ntrain=60000,ntest=10000,onehot=True):\n",
    "\tdata_dir = os.path.join(datasets_dir,'mnist/')\n",
    "\tfd = open(os.path.join(data_dir,'train-images-idx3-ubyte'))\n",
    "\tloaded = np.fromfile(file=fd,dtype=np.uint8)\n",
    "\ttrX = loaded[16:].reshape((60000,28*28)).astype(float)\n",
    "\n",
    "\tfd = open(os.path.join(data_dir,'train-labels-idx1-ubyte'))\n",
    "\tloaded = np.fromfile(file=fd,dtype=np.uint8)\n",
    "\ttrY = loaded[8:].reshape((60000))\n",
    "\n",
    "\tfd = open(os.path.join(data_dir,'t10k-images-idx3-ubyte'))\n",
    "\tloaded = np.fromfile(file=fd,dtype=np.uint8)\n",
    "\tteX = loaded[16:].reshape((10000,28*28)).astype(float)\n",
    "\n",
    "\tfd = open(os.path.join(data_dir,'t10k-labels-idx1-ubyte'))\n",
    "\tloaded = np.fromfile(file=fd,dtype=np.uint8)\n",
    "\tteY = loaded[8:].reshape((10000))\n",
    "\n",
    "\ttrX = trX/255.\n",
    "\tteX = teX/255.\n",
    "\n",
    "\ttrX = trX[:ntrain]\n",
    "\ttrY = trY[:ntrain]\n",
    "\n",
    "\tteX = teX[:ntest]\n",
    "\tteY = teY[:ntest]\n",
    "\n",
    "\tif onehot:\n",
    "\t\ttrY = one_hot(trY, 10)\n",
    "\t\tteY = one_hot(teY, 10)\n",
    "\telse:\n",
    "\t\ttrY = np.asarray(trY)\n",
    "\t\tteY = np.asarray(teY)\n",
    "\n",
    "\treturn trX,teX,trY,teY\n",
    "\n",
    "def plot_mnist_digit(image1, image2, name1, name2):\n",
    "    global count_attack\n",
    "    image1 = np.reshape(image1,[1,784])\n",
    "    image2 = np.reshape(image2,[1,784])\n",
    "    \n",
    "    image1 = np.reshape(image1, [28, 28])\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(image1, cmap=plt.cm.gray)\n",
    "    plt.xticks(np.array([]))\n",
    "    plt.yticks(np.array([]))\n",
    "    plt.savefig(name1)\n",
    "    \n",
    "    image2 = np.reshape(image2, [28, 28])\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(image2, cmap=plt.cm.gray)\n",
    "    plt.xticks(np.array([]))\n",
    "    plt.yticks(np.array([]))\n",
    "    plt.savefig(name2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Here, we are loading the MNIST data into the media/datasets folder\n",
    "* Initialized weights using init_weights\n",
    "* Cost function is defined and Theano expressions are updated\n",
    "* L1 and L2 equations are presented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST data Loaded\n"
     ]
    }
   ],
   "source": [
    "######## Training sizes and parameters taken from https://github.com/robertlacok/mnist-adversarial-examples #######\n",
    "\n",
    "datasets_dir = 'media/datasets/'\n",
    "srng = RandomStreams()\n",
    "\n",
    "# set TRAINING to True if you want to train the model else to load learned model set TRAINING to False\n",
    "TRAINING = True\n",
    "\n",
    "print('MNIST data Loaded')\n",
    "Xtr, Xts, ytr, yts = mnist(onehot=True)\n",
    "\n",
    "# Initialize theano variables for X, Y, and shared variables for weights\n",
    "X = T.fmatrix()\n",
    "Y = T.fmatrix()\n",
    "\n",
    "if TRAINING:\n",
    "    # For training of the net, we initialize weights to random values\n",
    "    w_h = init_weights((784, 625))\n",
    "    w_h2 = init_weights((625, 625))\n",
    "    w_o = init_weights((625, 10))\n",
    "    params = [w_h, w_h2, w_o]\n",
    "else:\n",
    "    # To run experiments, just read weights we learned before\n",
    "    print('Loading model...')\n",
    "    with open('LearnedParams.model','rb') as fp:\n",
    "        params = cPickle.load(fp)\n",
    "    w_h, w_h2, w_o = params\n",
    "\n",
    "# Dropout model for training\n",
    "noise_h, noise_h2, noise_py_x = model(X, w_h, w_h2, w_o, 0.2, 0.5)\n",
    "# Use all-weights model for prediction\n",
    "h, h2, py_x = model(X, w_h, w_h2, w_o, 0., 0.)\n",
    "y_x = T.argmax(py_x, axis=1)\n",
    "\n",
    "# To find confidence of test set use the following value of y_x\n",
    "y_x1 = T.max(py_x, axis = 1)\n",
    "# Define cost and update theano expressions\n",
    "\n",
    "l1 = abs(w_h).sum() + abs(w_h2).sum() + abs(w_o).sum()\n",
    "l2 = (w_h**2).sum() + (w_h2**2).sum() + (w_o**2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We are keeping L1 and L2 Coefficients as 0.0001\n",
    "* Defined Cost and Train and predicted using theano functions\n",
    "* Trained MNIST data for 5 Epochs\n",
    "* Accuracy, Confidence of L1, L2 Coeffients are presented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1coef = 0.0001, l2coef = 0.0001\n",
      "Training MNIST data...\n",
      "Accuracy is:     0.9639\n",
      "Confidence is:     0.953655526234\n"
     ]
    }
   ],
   "source": [
    "################################################# Our Part of the code #######################################################\n",
    "\n",
    "#=================== Parameters to change ===============================#\n",
    "l1coef = 0.0001 \n",
    "l2coef = 0.0001\n",
    "#=======================================================================#\n",
    "\n",
    "print(\"l1coef = {0:.4f}, l2coef = {1:.4f}\" .format(l1coef,l2coef))\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(noise_py_x, Y)) + l1coef * l1 + l2coef * l2\n",
    "updates = RMSprop(cost, params, lr=0.001)\n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=updates, allow_input_downcast=True)\n",
    "predict = theano.function(inputs=[X], outputs=y_x, allow_input_downcast=True)\n",
    "predict_conf = theano.function(inputs=[X], outputs=y_x1, allow_input_downcast=True)\n",
    "\n",
    "if TRAINING:\n",
    "    print('Training MNIST data...')\n",
    "    # Train in 5 epochs\n",
    "    for k in range(5):\n",
    "        # Select minibatch and train\n",
    "        for start, end in zip(range(0, len(Xtr), 128), range(128, len(Xtr), 128)):\n",
    "            cost = train(Xtr[start:end], ytr[start:end])\n",
    "        # In each step save the learned weights\n",
    "        with open('LearnedParams.model','wb') as fp:\n",
    "            cPickle.dump(params,fp)\n",
    "    print(\"Accuracy is:    \",np.mean(np.argmax(yts, axis=1) == predict(Xts)))\n",
    "    print(\"Confidence is:    \", np.mean(predict_conf(Xts)))\n",
    "    \n",
    "###### Creating Adversarial Examples ######\n",
    "cost_ad = T.mean(T.nnet.categorical_crossentropy(py_x, Y))\n",
    "get_grad = theano.function(inputs=[X, Y], outputs=T.grad(cost_ad, X), allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* EPS values are taken as 0.05, 0.075, 0.15, 0.175, 0.20\n",
    "* Adversarial Set Accuracy and Confidence are presented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial set Accuracy, e= 0.05 :\t\t\t 0.8289\n",
      "Adversarial set Confidence:\t\t\t\t 0.875214622639\n",
      "================================================================================\n",
      "Adversarial set Accuracy, e= 0.075 :\t\t\t 0.703\n",
      "Adversarial set Confidence:\t\t\t\t 0.825596126647\n",
      "================================================================================\n",
      "Adversarial set Accuracy, e= 0.15 :\t\t\t 0.2791\n",
      "Adversarial set Confidence:\t\t\t\t 0.734209334553\n",
      "================================================================================\n",
      "Adversarial set Accuracy, e= 0.175 :\t\t\t 0.1762\n",
      "Adversarial set Confidence:\t\t\t\t 0.728741312186\n",
      "================================================================================\n",
      "Adversarial set Accuracy, e= 0.2 :\t\t\t 0.1076\n",
      "Adversarial set Confidence:\t\t\t\t 0.731223268518\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "################################################# Our Part of the code #######################################################\n",
    "\n",
    "#============================Parameter to change ========================================#\n",
    "eps_values = [0.05, 0.075, 0.15, 0.175, 0.20] \n",
    "#========================================================================================#\n",
    "\n",
    "for EPS in eps_values:\n",
    "    eps = EPS\n",
    "    adX = []\n",
    "    for i in range(len(Xts)):\n",
    "        gs = get_grad(Xts[i:i+1], yts[i:i+1]).T[:,0]\n",
    "        img_ad = Xts[i] + eps * np.sign(gs) \n",
    "        adX.append(img_ad)\n",
    "\n",
    "    # Find accuracy of the classifier on the test set and adversarial set\n",
    "    print('Adversarial set Accuracy, e=', eps, ':\t\t\t', np.mean(np.argmax(yts, axis=1) == predict(adX)))\n",
    "    print('Adversarial set Confidence:\t\t\t\t', np.mean(predict_conf(adX)))\n",
    "    print('================================================================================')\n",
    "    \n",
    "    ## saves mnist images perturbed with epsilon values.\n",
    "    #for i in range(5):     \n",
    "        #plot_mnist_digit(Xts[i], adX[i], 'test_img_{}_{}.jpg'.format(i,eps),'less_ad_img_{}_{}.jpg'.format(i,eps))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
