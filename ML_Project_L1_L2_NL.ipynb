{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is code for finding optimal L1 and L2 coefficients to improve learning on adversarial images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Deepak/anaconda/lib/python3.6/site-packages/matplotlib/__init__.py:1401: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    }
   ],
   "source": [
    "#importing\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "import numpy as np\n",
    "import pickle as cPickle\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "matplotlib.use('Agg')\n",
    "#from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Definitions\n",
    "# Convert into correct type for theano\n",
    "def floatX(X):\n",
    "    return np.asarray(X, dtype=theano.config.floatX)\n",
    "\n",
    "# Weights are shared theano variables\n",
    "def init_weights(shape):\n",
    "    return theano.shared(floatX(np.random.randn(*shape) * 0.01))\n",
    "\n",
    "# RMSProp to update weights\n",
    "def RMSprop(cost, params, lr=0.001, rho=0.9, epsilon=1e-6):\n",
    "    grads = T.grad(cost=cost, wrt=params)\n",
    "    updates = []\n",
    "    for p, g in zip(params, grads):\n",
    "        acc = theano.shared(p.get_value() * 0.)\n",
    "        acc_new = rho * acc + (1 - rho) * g ** 2\n",
    "        gradient_scaling = T.sqrt(acc_new + epsilon)\n",
    "        g = g / gradient_scaling\n",
    "        updates.append((acc, acc_new))\n",
    "        updates.append((p, p - lr * g))\n",
    "    return updates\n",
    "\n",
    "# Dropout regularization \n",
    "def dropout(X, p=0.):\n",
    "    if p > 0:\n",
    "        retain_prob = 1 - p\n",
    "        X *= srng.binomial(X.shape, p=retain_prob, dtype=theano.config.floatX)\n",
    "        X /= retain_prob\n",
    "    return X\n",
    "\n",
    "# Neural network model, 3 fully connected layers\n",
    "def model(X, w_h, w_h2, w_o, p_drop_input, p_drop_hidden):\n",
    "\t# Input layer: dropout + relu \n",
    "    X = dropout(X, p_drop_input)\n",
    "    h = T.nnet.relu(T.dot(X, w_h))\n",
    "\n",
    "\t# Hidden layer: dropout + relu \n",
    "    h = dropout(h, p_drop_hidden)\n",
    "    h2 = T.nnet.relu(T.dot(h, w_h2))\n",
    "\t\n",
    "\t# Output layer: dropout + softmax \n",
    "    h2 = dropout(h2, p_drop_hidden)\n",
    "    py_x = T.nnet.softmax(T.dot(h2, w_o))\n",
    "    return h, h2, py_x\n",
    "\n",
    "def one_hot(x,n):\n",
    "\tif type(x) == list:\n",
    "\t\tx = np.array(x)\n",
    "\tx = x.flatten()\n",
    "\to_h = np.zeros((len(x),n))\n",
    "\to_h[np.arange(len(x)),x] = 1\n",
    "\treturn o_h\n",
    "\n",
    "def mnist(ntrain=60000,ntest=10000,onehot=True):\n",
    "\tdata_dir = os.path.join(datasets_dir,'mnist/')\n",
    "\tfd = open(os.path.join(data_dir,'train-images-idx3-ubyte'))\n",
    "\tloaded = np.fromfile(file=fd,dtype=np.uint8)\n",
    "\ttrX = loaded[16:].reshape((60000,28*28)).astype(float)\n",
    "\n",
    "\tfd = open(os.path.join(data_dir,'train-labels-idx1-ubyte'))\n",
    "\tloaded = np.fromfile(file=fd,dtype=np.uint8)\n",
    "\ttrY = loaded[8:].reshape((60000))\n",
    "\n",
    "\tfd = open(os.path.join(data_dir,'t10k-images-idx3-ubyte'))\n",
    "\tloaded = np.fromfile(file=fd,dtype=np.uint8)\n",
    "\tteX = loaded[16:].reshape((10000,28*28)).astype(float)\n",
    "\n",
    "\tfd = open(os.path.join(data_dir,'t10k-labels-idx1-ubyte'))\n",
    "\tloaded = np.fromfile(file=fd,dtype=np.uint8)\n",
    "\tteY = loaded[8:].reshape((10000))\n",
    "\n",
    "\ttrX = trX/255.\n",
    "\tteX = teX/255.\n",
    "\n",
    "\ttrX = trX[:ntrain]\n",
    "\ttrY = trY[:ntrain]\n",
    "\n",
    "\tteX = teX[:ntest]\n",
    "\tteY = teY[:ntest]\n",
    "\n",
    "\tif onehot:\n",
    "\t\ttrY = one_hot(trY, 10)\n",
    "\t\tteY = one_hot(teY, 10)\n",
    "\telse:\n",
    "\t\ttrY = np.asarray(trY)\n",
    "\t\tteY = np.asarray(teY)\n",
    "\n",
    "\treturn trX,teX,trY,teY\n",
    "\n",
    "def plot_mnist_digit(image1, image2, name1, name2):\n",
    "    global count_attack\n",
    "    image1 = np.reshape(image1,[1,784])\n",
    "    image2 = np.reshape(image2,[1,784])\n",
    "    #print 'test image confidence' , np.mean(predict_conf(image1)), 'adversarial image confidence', np.mean(predict_conf(image2))\n",
    "    if (predict(image1) != predict(image2)):\n",
    "        count_attack = count_attack + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST data Loaded\n"
     ]
    }
   ],
   "source": [
    "#Loading MNIST data\n",
    "datasets_dir = 'media/datasets/'\n",
    "srng = RandomStreams()\n",
    "TRAINING = True\n",
    "\n",
    "print('MNIST data Loaded')\n",
    "trX, teX, trY, teY = mnist(onehot=True)\n",
    "\n",
    "# Initialize theano variables for X, Y, and shared variables for weights\n",
    "X = T.fmatrix()\n",
    "Y = T.fmatrix()\n",
    "\n",
    "if TRAINING:\n",
    "    # For training of the net, we initialize weights to random values\n",
    "    w_h = init_weights((784, 625))\n",
    "    w_h2 = init_weights((625, 625))\n",
    "    w_o = init_weights((625, 10))\n",
    "    params = [w_h, w_h2, w_o]\n",
    "else:\n",
    "    # To run experiments, just read weights we learned before\n",
    "    print('Loading model...')\n",
    "    with open('LearnedParamsL1_2.model','rb') as fp:\n",
    "        params = cPickle.load(fp)\n",
    "    w_h, w_h2, w_o = params\n",
    "\n",
    "# Dropout model for training\n",
    "noise_h, noise_h2, noise_py_x = model(X, w_h, w_h2, w_o, 0.2, 0.5)\n",
    "# Use all-weights model for prediction\n",
    "h, h2, py_x = model(X, w_h, w_h2, w_o, 0., 0.)\n",
    "y_x = T.argmax(py_x, axis=1)\n",
    "\n",
    "# To find confidence of test set use the following value of y_x\n",
    "y_x1 = T.max(py_x, axis = 1)\n",
    "# Define cost and update theano expressions\n",
    "\n",
    "l1 = abs(w_h).sum() + abs(w_h2).sum() + abs(w_o).sum()\n",
    "l2 = (w_h**2).sum() + (w_h2**2).sum() + (w_o**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MNIST data...\n",
      "0 :   0.9355\n",
      "1 :   0.9619\n",
      "2 :   0.9728\n",
      "3 :   0.9736\n",
      "4 :   0.9763\n",
      "5 :   0.9752\n",
      "6 :   0.9773\n",
      "7 :   0.9763\n",
      "8 :   0.9789\n",
      "9 :   0.9795\n",
      "10 :   0.9771\n",
      "11 :   0.9823\n",
      "12 :   0.9804\n",
      "13 :   0.9812\n",
      "14 :   0.9815\n",
      "15 :   0.9818\n",
      "16 :   0.9814\n",
      "17 :   0.9818\n",
      "18 :   0.9803\n",
      "19 :   0.9819\n",
      "20 :   0.9816\n",
      "21 :   0.9827\n",
      "22 :   0.9818\n",
      "23 :   0.9821\n",
      "24 :   0.982\n",
      "25 :   0.9828\n",
      "26 :   0.9823\n",
      "27 :   0.9821\n",
      "28 :   0.983\n",
      "29 :   0.9836\n",
      "30 :   0.9821\n",
      "31 :   0.9826\n",
      "32 :   0.9819\n",
      "33 :   0.983\n",
      "34 :   0.9819\n",
      "35 :   0.9833\n",
      "36 :   0.9827\n",
      "37 :   0.9835\n",
      "38 :   0.9834\n",
      "39 :   0.9832\n",
      "40 :   0.9835\n",
      "41 :   0.9827\n",
      "42 :   0.9826\n",
      "43 :   0.9833\n",
      "44 :   0.9829\n",
      "45 :   0.9826\n",
      "46 :   0.9835\n",
      "47 :   0.984\n",
      "48 :   0.9846\n",
      "49 :   0.9839\n"
     ]
    }
   ],
   "source": [
    "#l1 and l2 coefficients & Training Data\n",
    "#=================== Parameters to chnge ===============================#\n",
    "l1coef = [0.0,0.00001,0.0001]\n",
    "l2coef = [0.0,0.00001,0.0001]\n",
    "#=======================================================================#\n",
    "\n",
    "for i in l1coef:\n",
    "    for j in l2coef:\n",
    "        print(\"l1coef = %f, l2coef = %f\" %(i,j))\n",
    "        cost = T.mean(T.nnet.categorical_crossentropy(noise_py_x, Y)) + i * l1 + j * l2\n",
    "        updates = RMSprop(cost, params, lr=0.001)\n",
    "\n",
    "        # Define train and predict theano functions\n",
    "        train = theano.function(inputs=[X, Y], outputs=cost, updates=updates, allow_input_downcast=True)\n",
    "\n",
    "        predict = theano.function(inputs=[X], outputs=y_x, allow_input_downcast=True)\n",
    "        predict_conf = theano.function(inputs=[X], outputs=y_x1, allow_input_downcast=True)\n",
    "        print('Training MNIST data...')\n",
    "        if TRAINING:\n",
    "            # Train in 50 epochs\n",
    "            for i in range(50):\n",
    "                # Select minibatch and train\n",
    "                for start, end in zip(range(0, len(trX), 128), range(128, len(trX), 128)):\n",
    "                    cost = train(trX[start:end], trY[start:end])\n",
    "                # Show test set accuracy. Its cost is not used for optimization,\n",
    "                # it is just to show progress.\n",
    "                #print(i, ':  ', np.mean(np.argmax(teY, axis=1) == predict(teX)))\n",
    "                # In each step save the learned weights\n",
    "                with open('LearnedParamsL1.model','wb') as fp:\n",
    "                    cPickle.dump(params,fp)\n",
    "            print(\"Accuracy is:    \",np.mean(np.argmax(teY, axis=1) == predict(teX)))\n",
    "            print(\"Confidence is:    \", np.mean(predict_conf(teX)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
